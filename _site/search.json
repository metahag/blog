[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "eLucidate science",
    "section": "",
    "text": "Open Data (in Disability Research)\n\n\n\n\n\n\n\nopen science\n\n\nreproducibility\n\n\n\n\nTips and resources for FAIRly sharing your data\n\n\n\n\n\n\nJul 10, 2024\n\n\nLucija Batinović\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction\n\n\n\n\n\n\n\ngeneral\n\n\n\n\nWhat can you find on this site?\n\n\n\n\n\n\nJun 22, 2024\n\n\nLucija Batinović\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/introduction/index.html",
    "href": "posts/introduction/index.html",
    "title": "Introduction",
    "section": "",
    "text": "True to my procrastinating personality, I have reached a point in my PhD journey where I boldly decide to start blogging about the interesting (to me at least) topics I am familiar with. As I despise writing with all my being, it is only natural that I take writing as my next hobby.\nIf you happen to stumble upon this site, consider this blog as my personal rant space and activate critical thinking when reading - I might be speaking nonsense. In fact, if you notice nonsense, please contact me so I can correct it.\nMy background is available and up-to-date (wishful thinking lmao) in the About section, and my focus here will be mostly on open science, reproducibility, (complaining about) research quality in special education, and my love for R.\nI will be sharing thoughts on new research, short guides related to reproducibility and open science practices, and shameless plugs. While I plan to write mostly in English, some posts will be in Croatian, or both.\nComing to the end of this introduction post, I am actually excited to start this journey, so who knows, maybe there’s hope for us after all. Hope you enjoy, pozdrav!"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "eLucidate Science is a collection of guides and tips for (under)graduate students and others interested in learning about open and reproducible science. Articles are based on my experience as a PhD student and reproducibility reviewer for Meta-Psychology."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About",
    "section": "Education",
    "text": "Education\nLinköping University | Linköping, Sweden PhD in Disability Research | Jan 2022 - present\nLinnaeus University | Växjö, Sweden M.Sc. in Work and Organizational Psychology | 2019 - 2021\nUniversity of Zadar | Zadar, Croatia Bachelor of Psychology | 2016 - 2019"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "About",
    "section": "Experience",
    "text": "Experience\nEditorial Assistant and Reproducibility Coordinator at Meta-Psychology | Linnaeus University | 2021 - present\nResearch Assistant | Linnaeus University | 2021 - 2022"
  },
  {
    "objectID": "posts/open_science/index.html",
    "href": "posts/open_science/index.html",
    "title": "Open Data (in Disability Research)",
    "section": "",
    "text": "Why should you share your data? Because sharing is caring. It is 2024, we are in an environmental crisis, and collecting data and keeping it to yourself should be a crime against humanity. Now that you’re guilted into it, it is only fair I help you change.\nMost common excuse for keeping data private is privacy concerns, which is a legitimate reason and a problem that is yet to be fully solved. This post offers some tips on how to share data in a safer way.\nSharing data today is becoming a beneficial act to the data curators (i.e., you who are creating and maintaining the datasets) as well, not only to everyone else who can reuse that data, because properly sharing datasets allows others to cite your work. Properly collected, curated and shared data is becoming as valuable as publishing journal articles (maybe I’m exaggerating, but this is certainly how things should be!).\nLet’s start with defining open data, so there can’t be any arguments on semantics. I will refer to the FAIR principles, although I would argue that “open data” means different things to different entities. FAIR stands for Findable, Accessible, Interoperable and Reusable data.\nI would try to translate their principles as open (i.e., FAIR) data being: a unique file, containing only variables and values (regardless of the file type, e.g., .txt, .json, etc.) that can be used as is, or wrangled with available analytical tools. Notice that with the current development of LLMs, this will start encompassing a much larger number of file types.\nFor example, you can probably take a poorly described dataset, formatted in a complicated, nested table, and saved as a PDF, import it to chatGPT and it will export a usable Excel sheet with that data. I would argue this does not qualify that PDF as FAIR data, and I would for these purposes equate AI power to manual labor, and if that is necessary, your (open) data is not FAIR.\nThere are millions of nuances here probably, and most outliers will probably be pointless to cover because it is safe to assume most data in social sciences is simply tabular. I will only focus on that type of data in this post, and might do a separate post for neuro/image-based data, although the basic principles stay the same.\nWe will go through each step using a simulated dataset. Wherever possible, steps will be shown in R, Python, and Jamovi as a GUI alternative. You can of course use SPSS, MATLAB or other proprietary softwares, but if you don’t plan to use open source alternatives, you’re on your own."
  },
  {
    "objectID": "posts/open_science/index.html#first-its-raw",
    "href": "posts/open_science/index.html#first-its-raw",
    "title": "Open Data (in Disability Research)",
    "section": "1 First it’s raw",
    "text": "1 First it’s raw\nWhether you conduct an online survey, experiment on a local machine, pencil-paper, video-recording, etc., you will wind up with raw data in some form. Some sources define raw data as “collected from the source”. It is hard to say whether we have multiple raw data stages, and when it becomes processed.\nPresumably, raw data would only be data that is in the source format, i.e., a video-recording, html file downloaded from SurveyMonkey, filled out paper survey, etc., which would make a tabular form of the variables collected with various sources processed to some degree. For the purposes of this blog, raw data will be considered the first iteration of the tabular form. For example, if you collected your data through a paper survey, we would consider raw data to be an Excel file containing answers from all participants that someone transferred from paper to Excel.\nNote that Excel is also a proprietary software, and saving your data should be done in open source formats (e.g., files with extension like .csv, .txt, .tsv), which can be opened without paying for a software licence. However, R and Python can read Excel files even if you don’t have access to Microsoft Excel. Still, it is good practice to save your data in a machine-readable, open format. Some will argue however, that saving Excel files as a .csv file might lead to data loss and errors. Unless you have done some kind of preprocessing in Excel, this should not be overly concerning, but for safety, keep an Excel copy saved as well.\nRaw data will most likely contain identifiers, and should rarely be openly deposited due to possible ethical and privacy violations.\n\n1.1 Anonymize the dataset by removing identifiying columns\n\nRPythonJamovi\n\n\n\n## import data and drop id column in base r\n# import raw data (make sure to set your directory \n# where your data is located)\nbase_data <- read.csv(\"data.csv\")  \n\n# create a new object for additional wrangling \nanon_base_data <- base_data |>\n  subset(select = -ParticipantID) \n\n## tidyverse version\nlibrary(tidyverse)\n# import raw data \ntidyv_data <- read_csv(\"data.csv\") \n# create a new object for additional wrangling \nanon_tidyv_data <- tidyv_data %>% select(-ParticipantID) \n\n# save the dataset as a csv file\n# write_csv tidyverse alternative\nwrite.csv(anon_base_data, \"data.csv\") \n\n\n\n\nimport pandas as pd\nraw_data = pd.read_csv(\"data.csv\")\n\n# drop identifying columns(s)\nnew_data = raw_data.drop(columns = ['ParticipantID'])\n\n# save the dataset as a csv file\nnew_data.to_csv(\"data.csv\")\n\n\n\n\n\n\nRemove ID column in Jamovi\n\n\n\n\n\n\n\n1.2 Anonymize data by creating synthetic equivalents\nSensitive data, particularly when it pertains to populations with low incidence disabilities may still be identifiable, even when we drop demographic information or identifying descriptors. To be able to share the code and make it reproducible, one way to share the data is to create synthetic datasets based on the properties of the original one.\nI will show one example in R and Python, with the synthpop R package, and the sdv Python package, but there are multiple packages that could fit your needs in both languages. These packages allow you to recreate your dataset and keep original properties (i.e., type of data for each variable) and relations between them (e.g., mean or correlation values) as much as possible.\nSynthetic data fidelity depends on the size and quality of the original data, but it can at least serve as a dataset that allows reproducing the code you used to conduct analyses. Each package (library) also provides functions that help you estimate how well the synthetic data corresponds to the original.\n\nRPython\n\n\n\nlibrary(synthpop)\nsyn_data <- syn(anon_base_data,\n                method = \"parametric\", \n                seed = 123)\n\n# compare the similarity between the synthetic and original data\ncompare(syn_data$syn, anon_base_data) \n\n\n\n\nimport sdv\nfrom sdv.metadata import SingleTableMetadata\nfrom sdv.single_table import GaussianCopulaSynthesizer\nfrom sdv.evaluation.single_table import run_diagnostic, evaluate_quality\nfrom sdv.evaluation.single_table import get_column_plot\nimport random\n\nrandom.seed(2024)\n# create the metadata of the dataset\nmetadata = SingleTableMetadata()\nmetadata.detect_from_dataframe(new_data)\n\n# select the type of sampling\nsynthesizer = GaussianCopulaSynthesizer(metadata)\n# create the synthetic data\nsynthesizer.fit(new_data)\nsynthetic_data = synthesizer.sample(num_rows=20)\n\n# compare the similarity between the synthetic and original data\n# basic validity checks\nvalidity = run_diagnostic(new_data, synthetic_data, metadata)\n\n# statistical similarity\nsimilarity = evaluate_quality(new_data, synthetic_data, metadata)\n\nSynthetic datasets have been getting attention for some time now in healthcare research, so you can read up more about them here and here, and disability research (and social sciences generally) can absolutely benefit from them as well."
  },
  {
    "objectID": "posts/open_science/index.html#prepare-metadatacodebook",
    "href": "posts/open_science/index.html#prepare-metadatacodebook",
    "title": "Open Data (in Disability Research)",
    "section": "2 Prepare metadata/codebook",
    "text": "2 Prepare metadata/codebook\nFAIR data reuqires you to provide “data about your data” (i.e., metadata) which allows users to understand what the dataset contains in terms of measured variables, name meaning, permitted and forbidden values, etc.\nFor example, you might have a dataset containing a hundred variables you collected from a large battery of cognitive tests. Providing that dataset to others is close to useless if the users do not know what each variable was measuring, what was the possible range of values for each variable and what was the intended data type (e.g., integer).\nOnce again, there is no clear consensus on naming and defining metadata, so I will use it interchangeably with codebook here, as some fields call files containing that information “codebooks”. Section 4 at the end provides links to guides that can help you create good metadata files.\nOnce your data is deidentified, you can proceed to clean it and wrangle however you need it for your analyses. Once you have both the deidentified raw data and the clean (final) dataset, you can prepare for sharing those files.\nTo provide FAIR data, you now have the data saved as a .csv file. Great! Now we need a codebook and quality metadata for the dataset. A codebook is a file accompanying the dataset which explains each variable, e.g., data type, range of values, names, descriptions, etc. You can write this by yourself, but R provides a package that creates a detailed codebook for you. codebook allows you to also create metadata for your datasets.\n\nRJamovi\n\n\n\nlibrary(codebook)\n\n# create a codebook markdown\n# this codebook also provides metadata\ncodebook(anon_base_data)\n\n# assign attributes to the data manually \nmetadata(anon_base_data$questionOne <- \"First question in the scale\",\n         anon_base_data$questionTwo <- \"Second question in the scale\")\n\n\n\n\n\n\nProvide metadata descriptions to each variable in Jamovi"
  },
  {
    "objectID": "posts/open_science/index.html#now-its-ready-to-be-shared",
    "href": "posts/open_science/index.html#now-its-ready-to-be-shared",
    "title": "Open Data (in Disability Research)",
    "section": "3 Now it’s ready to be shared",
    "text": "3 Now it’s ready to be shared\nNow your data is ready to be publicly shared! There is no one best repository for data, so here is an overview of a non-exhaustive list of popular options.\n\nData Repositories\n\n\nRepository\nDOI\nVersion Control\nLicence Alternatives\n\n\n\n\nZenodo\nYes\nYes\nYes\n\n\nOSF\nYes\nYes\nYes\n\n\nfigshare\nYes\nYes\nYes\n\n\n\n\n3.1 Example in OSF\nYou can share your data on OSF, as a new project or a project component tied to your existing project.\nI recommend the following structure:\n\nCreate a project on OSF for your study\nCreate a new component of that project and select the “Data” category\nTo the “Data” component, upload your data files, codebooks and other accompanying files if necessary\nIn the Wiki section of the component, explain where the data comes from, who collected it, when, who the data curators are (this can also be a standalone README file)\nAssign data curators as contributors of the component\nRegister your component under the open registration form to obtain a shareable DOI and make the data immutable and time stamped\n\nNow your data is shared according to the FAIR principles!"
  },
  {
    "objectID": "posts/open_science/index.html#sec-resources",
    "href": "posts/open_science/index.html#sec-resources",
    "title": "Open Data (in Disability Research)",
    "section": "4 Resources",
    "text": "4 Resources\nThere is plenty more that goes into creating robust datasets which can easily be expanded and built upon. For ideas and guides on how to create flawless datasets, here are some resources:\n\nPsych-DS - a community-created set of standards for datasets in psychology research (which is heavily applicable to the rest of social sciences)\nJournal of Open Psychology Data - a journal that “publishes peer-reviewed data papers describing psychology datasets with high reuse potential” which can serve as inspiration for creating high quality datasets (thanks to Marta Topor for the suggestion!)\nBIDS - provides standards for creating metadata files for brain imaging data\nMaking data FAIR - detailed guides on how to make your data FAIR"
  }
]